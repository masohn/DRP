{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Drug Feature Extraction with Transformer Encoder\n",
    "\n",
    "In this Jupyter notebook, a transformer encoder is used to obtain drug feature representations from the SMILES strings.\n",
    "\n",
    "<br>\n",
    "\n",
    "### File Requirements\n",
    "\n",
    "The following files are required in the `data/STEP01` folder:\n",
    "1. [ChEMBL_SMILES_2kk.csv](https://www.ebi.ac.uk/chembl/explore/compounds/)\n",
    "2. SPE_ChEMBL_1500freq.txt - Custom tokens obtained by STEP01_SPE.ipynb\n",
    "\n",
    "<br>\n",
    "\n",
    "### Output\n",
    "The trained model, depending on the selected training size, in this case 50000 SMILES strings: â€œmodels/SMILES_ENCODER_50k.pth\".\n",
    "\n",
    "<br>\n",
    "\n",
    "### Evaluation\n",
    "Evaluation can be performed on the entire dataset, subset of the dataset and on all GDSC SMILES strings. \n",
    "\n",
    "The evaluation function calculates the accuracy of SMILES reconstruction, the average Levenshtein distance between the original and reconstructed SMILES strings, and the average length of mismatched SMILES strings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8124e6418c2e93cc"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import Levenshtein"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36f0dac6894af720",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9ae7e5d9c75ba33"
  },
  {
   "cell_type": "code",
   "source": [
    "# Training data\n",
    "df = pd.read_csv(\"data/STEP01/ChEMBL_SMILES_2kk.csv\")\n",
    "\n",
    "# Load custom tokens from SMILES PAIR Encoding\n",
    "with open(\"data/STEP01/SPE_ChEMBL_1500freq.txt\", \"r\") as f:\n",
    "    custom_tokens = [line.strip().split()[0] for line in f]\n",
    "\n",
    "# Select 50000 SMILES strings for training\n",
    "smiles_training = df.iloc[:50000, 0]\n",
    "train_smiles, val_smiles = train_test_split(smiles_training, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0568e389684d07",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility functions and torchtext vocabulary creation\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25a6bd3a49095081"
  },
  {
   "cell_type": "code",
   "source": [
    "def custom_tokenizer(smiles_string):\n",
    "    \"\"\"\n",
    "    Tokenizes a SMILES string by splitting it into tokens based on custom tokens\n",
    "    :param smiles_string: The SMILES string to tokenize.\n",
    "    :return: list: A list of tokens.\n",
    "    \"\"\"\n",
    "    for token in custom_tokens:\n",
    "        if token in smiles_string:\n",
    "            smiles_string = smiles_string.replace(token, f' {token} ')\n",
    "    return smiles_string.split()\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    \"\"\"\n",
    "    Generator function to yield tokens from a data iterator\n",
    "    :param data_iter: An iterable of SMILES strings.\n",
    "    :return: A list of tokens for each SMILES string.\n",
    "    \"\"\"\n",
    "    for text in data_iter:\n",
    "        yield custom_tokenizer(text)\n",
    "\n",
    "\n",
    "# Build vocabulary with special tokens\n",
    "vocab = build_vocab_from_iterator(yield_tokens(smiles_training), specials=[\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "\n",
    "def encode_smiles_to_indices(smiles):\n",
    "    \"\"\"\n",
    "    Encodes a SMILES string into a sequence of integer indices.\n",
    "    :param smiles: The SMILES string to encode.\n",
    "    :return: A list of integer indices.\n",
    "    \"\"\"\n",
    "    return [vocab[\"<sos>\"]] + [vocab[token] for token in custom_tokenizer(smiles)] + [vocab[\"<eos>\"]]\n",
    "\n",
    "\n",
    "# Function to pad sequences to the same length\n",
    "max_len = max(len(encode_smiles_to_indices(smile)) for smile in smiles_training)\n",
    "\n",
    "\n",
    "def pad_sequence(seq, max_len):\n",
    "    \"\"\"\n",
    "    Pads a sequence to a specified length with the <pad> token.\n",
    "    :param seq: The sequence to pad.\n",
    "    :param max_len: The maximum length.\n",
    "    :return: The padded sequence.\n",
    "    \"\"\"\n",
    "    return seq + [vocab[\"<pad>\"]] * (max_len - len(seq))\n",
    "\n",
    "\n",
    "def smiles_to_padded_tensor(smiles):\n",
    "    \"\"\"\n",
    "    Encodes a SMILES string into a padded PyTorch tensor of integer indices.\n",
    "    :param smiles: The SMILES string to encode.\n",
    "    :return: The encoded SMILES string as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    sequence = encode_smiles_to_indices(smiles)\n",
    "    sequence = pad_sequence(sequence, max_len)\n",
    "    return torch.tensor(sequence).unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e07132d7a5761788",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer Encoder model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e35400dd8b7d9ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, num_layers, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_encoder = nn.TransformerEncoderLayer(embed_size, num_heads, dim_feedforward=512, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.pos_encoder, num_layers)\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        src = self.embedding(src) * math.sqrt(self.embed_size)\n",
    "        src = self.transformer_encoder(src, src_mask)\n",
    "        output = self.fc_out(src)\n",
    "        return output"
   ],
   "id": "ab49652533e4ea5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "911fa7d3d72e47a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, train_smiles_list, val_smiles_list, num_epochs=2, lr=0.001):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<pad>\"])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for smiles in train_smiles_list:\n",
    "            optimizer.zero_grad()\n",
    "            input_seq = smiles_to_padded_tensor(smiles)\n",
    "            target_seq = input_seq.clone()\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.view(-1, len(vocab)), target_seq.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss = 0\n",
    "            for smiles in val_smiles_list:\n",
    "                input_seq = smiles_to_padded_tensor(smiles)\n",
    "                target_seq = input_seq.clone()\n",
    "                input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "                output = model(input_seq)\n",
    "                loss = criterion(output.view(-1, len(vocab)), target_seq.view(-1))\n",
    "                epoch_val_loss += loss.item()\n",
    "        \n",
    "        # Print training and validation loss\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {epoch_train_loss / len(train_smiles_list)}, Validation Loss: {epoch_val_loss / len(val_smiles_list)}\")\n",
    "    \n",
    "    \n",
    "# Train the model\n",
    "model = TransformerModel(len(vocab), 512, 8, 3, 0.1)\n",
    "train_model(model, train_smiles, val_smiles)"
   ],
   "id": "3045d7ded1f38d37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), \"models/SMILES_ENCODER_50k.pth\")"
   ],
   "id": "515da900edbfd355",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4039340f476ca35"
  },
  {
   "cell_type": "code",
   "source": [
    "# Utility function to decode the model output\n",
    "def decode_sequence(input_seq):\n",
    "    model.eval()\n",
    "    input_seq = input_seq.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seq)\n",
    "    output_tokens = output.argmax(dim=-1)\n",
    "    decoded_tokens = []\n",
    "    for token_idx in output_tokens.squeeze().tolist():\n",
    "        token = vocab.lookup_token(token_idx)\n",
    "        if token == \"<eos>\":\n",
    "            break\n",
    "        decoded_tokens.append(token)\n",
    "    decoded_smiles = \"\".join(decoded_tokens).replace(\"<pad>\", \"\").replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    return decoded_smiles\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_reconstruction(smiles_list, print_mismatches):\n",
    "    correct_count = 0\n",
    "    total_levenshtein_distance = 0\n",
    "    total_mismatched_smiles_length = 0\n",
    "    mismatched_count = 0\n",
    "\n",
    "    for smiles in smiles_list:\n",
    "        input_seq = smiles_to_padded_tensor(smiles)\n",
    "        decoded_smiles = decode_sequence(input_seq)\n",
    "\n",
    "        if smiles == decoded_smiles:\n",
    "            correct_count += 1\n",
    "        else:\n",
    "            mismatched_count += 1\n",
    "            total_levenshtein_distance += Levenshtein.distance(smiles.upper(), decoded_smiles)\n",
    "            total_mismatched_smiles_length += len(smiles)\n",
    "            if print_mismatches:\n",
    "                print(f\"Original SMILES: {smiles}\")\n",
    "                print(f\"Reconstructed SMILES: {decoded_smiles}\")\n",
    "\n",
    "    total_count = len(smiles_list)\n",
    "    accuracy = correct_count / total_count * 100\n",
    "\n",
    "    if mismatched_count > 0:\n",
    "        average_levenshtein_distance = total_levenshtein_distance / mismatched_count\n",
    "        average_mismatched_smiles_length = total_mismatched_smiles_length / mismatched_count\n",
    "    else:\n",
    "        average_levenshtein_distance = 0\n",
    "        average_mismatched_smiles_length = 0\n",
    "\n",
    "    return accuracy, average_levenshtein_distance, average_mismatched_smiles_length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b8888f166b4a2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# For evaluation on the entire dataset: df.iloc[:, 0]\n",
    "# With my computational resources, this step takes about 7 hours.\n",
    "eval_data = df.iloc[400000:500000, 0]\n",
    "accuracy, leven, length = evaluate_reconstruction(eval_data, print_mismatches=False)\n",
    "print(f\"Accuracy of SMILES reconstruction: {accuracy:.2f}%\")\n",
    "print(f\"Average Levenshtein distance: {leven:.2f}\")\n",
    "print(f\"Average mismatched SMILES length: {length:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "169a8fda8d79f97f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate on the GDSC dataset\n",
    "gdsc_smiles = pd.read_csv(\"data/STEP00/ALL_SMILES.csv\")\n",
    "gdsc_smiles = gdsc_smiles.drop_duplicates(subset=[\"smiles\"])\n",
    "gdsc_smiles = gdsc_smiles[\"smiles\"]\n",
    "\n",
    "accuracy, leven, length = evaluate_reconstruction(gdsc_smiles, print_mismatches=True)\n",
    "print(f\"Accuracy of SMILES reconstruction: {accuracy:.2f}%\")\n",
    "print(f\"Average Levenshtein distance: {leven:.2f}\")\n",
    "print(f\"Average mismatched SMILES length: {length:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbb7abaf116f27b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
